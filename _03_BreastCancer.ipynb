{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "_03_BreastCancer.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPss/QjxjtPMyhrVfL/blax",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bltsezer/DataSet_Uuygulama/blob/main/_03_BreastCancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-uhkZNs0iTD"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class DataPreprocessor:\n",
        "    \n",
        "    def preprocess(self, train, test):\n",
        "        column_list = ['age', 'sex', 'on_thyroxine', 'query_on_thyroxine', 'on_antithyroid_medication', 'sick', 'pregnant', 'thyroid_surgery', 'I131_treatment', 'query_hypothyroid', 'query_hyperthyroid', 'lithium', 'goitre', 'tumor', 'hypopituitary', 'psych', 'TSH', 'T3', 'TT4', 'T4U', 'FTI', 'Class']\n",
        "        train = pd.DataFrame(train.iloc[:,0:22].values, columns=column_list)\n",
        "        test = pd.DataFrame(test.iloc[:,0:22].values, columns=column_list)\n",
        "        \n",
        "        return train, test\n",
        "    \n",
        "    def split_predictors(self, data):\n",
        "        \n",
        "        data_X = data.drop(['Class'], axis=1)\n",
        "        \n",
        "        data_y = data['Class']\n",
        "        \n",
        "        return data_X, data_y\n",
        "    \n",
        "    def scale_data(self, train_X, test_X):\n",
        "        \n",
        "        sc = StandardScaler()\n",
        "        train_X = sc.fit_transform(train_X)\n",
        "        test_X = sc.transform(test_X)\n",
        "        \n",
        "        return train_X, test_X\n",
        "    \n",
        "    def validation_split(self, train_X, train_y, test_size = 0.2, random_state = 1):\n",
        "        X_train, X_validation, y_train, y_validation = train_test_split(train_X, train_y, test_size = 0.2, random_state = 1)        \n",
        "        \n",
        "        return X_train, X_validation, y_train, y_validation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDsGxaj3020m"
      },
      "source": [
        "import pandas\n",
        "\n",
        "class DatasetLoader:\n",
        "    path = \"\"\n",
        "       \n",
        "    def __init__(self, path):\n",
        "        self.path = path\n",
        "        \n",
        "    def load(self):\n",
        "        \n",
        "        data = pandas.read_csv(self.path, header=None, sep=' ')\n",
        "        return data\n",
        "        \n",
        "    def print_shape(self, data):\n",
        "      \n",
        "        print(data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dx3zNKrm1IQn"
      },
      "source": [
        "import pickle\n",
        "import numpy\n",
        "import pandas\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "class ModelBuilder:\n",
        "    def classifier_model(self):\n",
        "        model = Sequential()\n",
        "        \n",
        "        model.add(Dense(48, kernel_initializer = 'uniform', input_dim=21, activation='relu'))\n",
        "        \n",
        "        model.add(Dropout(0.25))\n",
        "        \n",
        "        model.add(Dense(48, kernel_initializer = 'uniform', activation='relu'))\n",
        "        \n",
        "        model.add(Dropout(0.25))\n",
        "        \n",
        "        model.add(Dense(48, kernel_initializer = 'uniform', activation='relu'))\n",
        "        \n",
        "        model.add(Dropout(0.25))\n",
        "        \n",
        "        model.add(Dense(3, kernel_initializer = 'uniform', activation='softmax'))\n",
        "\n",
        "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "        \n",
        "        return model\n",
        "    \n",
        "    def get_classifier(self):\n",
        "        \n",
        "        classifier = KerasClassifier(build_fn = self.classifier_model, batch_size = 10, epochs = 100)\n",
        "        \n",
        "        return classifier\n",
        "    \n",
        "    def finalize_and_save(self, model, train_X, train_y, filename='../model/final_model'):\n",
        "        \n",
        "        model.fit(train_X, train_y)\n",
        "        \n",
        "        self.save_model(model, filename)\n",
        "        \n",
        "    def save_model(self, model, filename='../model/saved_model'):\n",
        "        \n",
        "        pickle.dump(model, open(filename, 'wb' ))\n",
        "        print(\"\\nModel is saved..\\n\")\n",
        "    \n",
        "    def load_model(self, model_filename):\n",
        "        \n",
        "        loaded_model = pickle.load(open(model_filename, 'rb' ))\n",
        "        \n",
        "        return loaded_model\n",
        "    \n",
        "    def validate(self, model, train_X, train_y):\n",
        "        results = cross_val_score(estimator = model, X = train_X, y = train_y, cv = 10, n_jobs = 3)\n",
        "        \n",
        "        print(\"\\nCross Validation - Accuracy : %.2f%% (%.2f%%)\\n\" % (results.mean()*100.0, results.std()*100.0))\n",
        "        \n",
        "    def evaluate(self, model, train_X, train_y, test_X, test_y):\n",
        "        model.fit(train_X, train_y, batch_size = 10, epochs = 100) \n",
        "        \n",
        "        y_test_pred = model.predict(test_X)\n",
        "        \n",
        "        cm = confusion_matrix(test_y, y_test_pred)\n",
        "        \n",
        "        print(\"\\nModel Evaluation - Accuracy is %.3f%% \\n\" % ((cm[0][0]+cm[1][1]+cm[2][2])*100/test_y.size))\n",
        "        \n",
        "    def check_prediction(self, model, test_X, test_y):\n",
        "        \n",
        "        y_test_pred = model.predict(test_X)\n",
        "        \n",
        "        \n",
        "        cm = confusion_matrix(test_y, y_test_pred)\n",
        "        \n",
        "        \n",
        "        y_test_pred = self.map_pred_class(y_test_pred)\n",
        "        \n",
        "        print(\"\\n............Predictions............\\n\")\n",
        "        print(y_test_pred.reshape(-1,1))\n",
        "        print(\"\\nTest Data - Accuracy: %.3f%% \\n\" % ((cm[0][0]+cm[1][1]+cm[2][2])*100/test_y.size))\n",
        "    \n",
        "    def save_predictions(self, model, test_X):\n",
        "        \n",
        "        predictions = model.predict(test_X)\n",
        "\n",
        "        predictions = self.map_pred_class(predictions)\n",
        "        \n",
        "        pandas.DataFrame(predictions).to_csv('../prediction/predictions.csv', index=False)\n",
        "        print(\"\\nSAVE..\\n\")\n",
        "    \n",
        "    def map_pred_class(self, preditions):\n",
        "        pred_map = ['Normal'  if(x==3) else 'Subnormal' if (x==2) else 'HyperThyroid'  for x in preditions]\n",
        "        \n",
        "        return numpy.array(pred_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfpYCRS42gkH"
      },
      "source": [
        "!wget \"http://cimalab.intec.co/applications/thyroid/maligns.zip\"\n",
        "\n",
        "!wget \"http://cimalab.intec.co/applications/thyroid/benigns.zip\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e67Guhg625I3"
      },
      "source": [
        "!unzip maligns.zip\n",
        "!unzip benigns.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihFN8bYk3CZT"
      },
      "source": [
        "!dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xENa43yF3GSd"
      },
      "source": [
        "!rm maligns.zip\n",
        "!rm benigns.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE5Mp_Ig3dup"
      },
      "source": [
        "!pwd\n",
        "# %cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPZFHmnL3nMb"
      },
      "source": [
        "!dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDgPEaeH2Ipq"
      },
      "source": [
        "   \n",
        "data_loader = DatasetLoader('bening')\n",
        "train = data_loader.load()\n",
        "\n",
        "data_loader = DatasetLoader('/maligns')\n",
        "test = data_loader.load()\n",
        "\n",
        "dp = DataPreprocessor()\n",
        "train, test = dp.preprocess(train, test)\n",
        "\n",
        "train_X, train_y = dp.split_predictors(train)\n",
        "test_X, test_y = dp.split_predictors(test)\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_val, y_train, y_val = dp.validation_split(train_X, train_y)\n",
        "\n",
        "\n",
        "X_train, X_val = dp.scale_data(X_train, X_val)\n",
        "\n",
        "mb = ModelBuilder()\n",
        "classifier = mb.get_classifier()        \n",
        "       \n",
        "mb.validate(classifier, X_train, y_train)\n",
        "\n",
        "mb.evaluate(classifier, X_train, y_train, X_val, y_val)\n",
        "\n",
        "\n",
        "\n",
        "train_X, test_X = dp.scale_data(train_X, test_X)\n",
        "\n",
        "mb.validate(classifier, train_X, train_y)\n",
        "\n",
        "classifier.fit(train_X, train_y, batch_size = 10, epochs = 100)\n",
        "\n",
        "\n",
        "mb.check_prediction(classifier, test_X, test_y)\n",
        "\n",
        "\n",
        "\n",
        "mb.save_model(classifier, '../model/final_model1')\n",
        "\n",
        "mb.save_predictions(classifier, test_X)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}